# Improving Sales Pipeline Insights with Sankey Charts

## TLDR

With improved CRM data that now links stage progressions with actual revenue activity, we are no longer constrained to static percentage-based metrics. This unlocks a more precise, action-oriented analysis through Sankey-style transition metrics—enabling more robust root cause automation, better pacing visibility, and insights into where and why clients drop off.

## Problem Statement

Previously, our sales pipeline tracking and root cause analysis relied on static percentages that Recommended Solutions are at today. For example, 40% in pitching, 30% in discovery, and 30% in actioned—percentages that summed to 100% but lacked directionality or context. This view is adopted in both DCMP Unidash and in SSPO's WBR.

However, this view:

* Masked regional pacing differences
* Obscured true drop-off points
* Couldn’t explain why or where transitions broke down

When relying on these metrics to do RCA:

> What we flagged as "anomalously high/low" might actually reflect faster transitions into the next phase, rather than a problem. RCA based on these false signals could mislead business decisions.

Now, with the CRM revamp, stage progression is tied to revenue-based adoption signals. Meanwhile, SSPO has started leveraging richer information like the % of RS that drop off prior to pitching (e.g., marked as Not Relevant or Not Actionable) in their WBR.

To better leverage this new structure in RCA—including:

* Quantifying (#, \$ and %) drop-off between stages
* Utilizing sales-logged reasons for lost pitches and blockers before lost/won

—**we need to change what we track in RCA** (and perhaps in Unidash and SSPO's WBR as well). Percentage-based stage totals no longer reflect how initiatives truly move—or fail to. Root cause automation built on these legacy metrics cannot fully capture the new data structure and opportunity space.

## Why This Matters: Benefits of Transition-Based Metrics

Switching to transition-based tracking enables:

### **Funnel Leakage Insights**

* Identify where and how much value is lost in stage transitions (e.g., Scoping → Pitching, Pitching → Actioned, Actioned → Adopted).
* Quantify dollar value lost at each transition and link to specific reasons.
* Derive actionable next steps from drop-off causes:

  * Early Stage → Pitching:

    * “Duplicate initiatives”, “Uncontactable”: are the inventory gaps considered when assigning those RS at quarter-start?&#x20;
  * Pitching → Actioned:

    * “Resource issues”: could suggest product/region stress.
  * Actioned → Adopted:

    * “Budget cuts”, “Performance concerns”: might require better expectation setting or targeting.
* Which region × product combinations exhibit the highest leakage?

### **Better Pacing and Blockage Visibility**

* Track how long initiatives sit in each stage.
* Spot stage congestion by region or product.
* Detect implicit blockages from dwell time—even when sales don't mark them explicitly.

### **More Precise Root Cause Automation**

* Compare transition rates to regional benchmarks or past quarters:

  * NA’s Pitching → Actioned rate is lower than global average
  * QoQ drop in Pitching → Actioned for Product X in NA is low due to tarrifs
* Attribute transition failures to CI patterns:

  * 3 interactions on "Technical Issues" within 10 days → increased probability of loss

## Potential Analytical Layers

| Layer                           | What to compute                                                                                                                                           | Why it’s useful                                                                                                                   |
| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| **1. Basic funnel**             | Stage-to-stage conversion rates and drop-off counts/revenue/percent                                                                                       | Highlights where and why a region or vertical loses value. Supports RCA, Unidash and WBR enhancement.                             |
| **2. CI intensity by stage**    | `avg_CI_per_initiative` per stage                                                                                                                         | Gauges whether early quitting or over-servicing is occurring. Supports RCA and reporting.                                         |
| **3. CI quality**               | Share of CIs that are tagged to advancing Solutions to next stage vs. general mentions of Solutions in the CI, XFN or manager cross-sell involvement rate | Helps quantify sales effort quality and involvement needed to move pipeline forward. Informs enablement and forecast reliability. |
| **4. Time-to-stage (survival)** | Kaplan-Meier curve: probability of *not* reaching Closed Won over time                                                                                    | Highlights stalling risk. Enables early warning for at-risk pipeline.                                                             |
| **5. Stage Markov model**       | P(stage t → t+1) matrix by region/product                                                                                                                 | Reveals if we’re likely to be off-track by EoQ. Helps leaders monitor flow health in one glance.                                  |

## CI as a Diagnostic Layer (Example Table)

We’ve also begun quantifying the average number of CIs (Client Interactions) needed for an initiative to move from one stage to the next (orange table).

For example:

* **1.46** CIs to go from Not Started → Early Stage
* **1.34** CIs to Early Stage → Pitching
* **1.88** CIs to  → Actioned
* **2.10–2.52** CIs to -> Partial/Full Adoption
* **Lost paths** are surprising: it takes \~0.2–0.3 CI to lose before pitching, but **post-pitch Closed Lost** shows more effort than Closed Won in some cases.

This allows us to:

* Identify whether lost deals result from too little effort—or too much futile effort.
* Investigate if high-effort losses are due to client profile mismatch or late disqualification.
* Calibrate effort thresholds per region/product and design exit criteria.

## Linking Operational and Revenue Metrics

The Sankey screenshot (Solutions % vs. Revenue %) shows how we can bridge operational data and revenue outcomes:

* **Top panel:** % of initiatives by stage (count-based)
* **Bottom panel:** % of revenue in pipeline by stage (value-based)

This enables:

* **Value alignment checks:** Is the pitch volume matched with high-value deals?
* **Revenue-at-risk surfacing:** Where is revenue bottlenecked despite high activity?
* **Precision on under/over-performance:**

Example:

* “Region X has 20% of its solutions stuck in Scoping, but that accounts for 40% of its revenue—this signals urgent high-value bottlenecks.”
* “Solution Y is pitched often but contributes little revenue—time to reassess targeting or product-market fit.”
* “Purely blaming a region for low stage percentage is misleading—when layered with revenue, it reveals they are prioritizing high-value deals.”

By aligning initiative counts with revenue weight, we move beyond volume-based RCA and empower value-driven action planning.

## Known Caveats

| Caveat                                                             | Mitigation                                                                                                             |
| ------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------- |
| CIs logged late or mis-tagged                                      | Filter by CIs within ±X days of each stage transition                                                                  |
| Reverse causality (“good deals draw more CI”)                      | Use lagged CI count before stage entry to avoid contamination                                                          |
| Right-censoring: many initiatives are unresolved until quarter-end | Treat in-flight transitions carefully. Use completion-aware metrics to avoid misleading conclusions during the quarter |

## JTBD

- [x] DS: Define and propose new transition-based metrics (this doc) and map each to a testable hypothesis ([linked sheet to be added])
- [ ] DS & SSPO: Jointly review and refine the metric–hypothesis mapping to ensure alignment and completeness
- [ ] DS: Conduct RCA using the new metrics and associated hypotheses
- [ ] DS & SSPO: Evaluate whether the new views improve insight clarity and decision usefulness in Unidash/WBR compared to existing metrics
- [ ] DE: Implement and productionize the new metric logic in Unidash and WBR dashboards