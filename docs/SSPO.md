## 1 Â· What is already automated?

| Metric layer       | Hypothesis type                                                   | Output today                   |
| ------------------ | ----------------------------------------------------------------- | ------------------------------ |
| L4 Operational KPI | **Directional** (ranked score)                                    | âœ” autoâ€‘refresh into WBR slides |
|                    | **Depthâ€‘spotter** (lagging / outperforming L8)                    | in Bento Notebook              |
|                    | **Productâ€‘mix** (index vs ROW)                                    | in Bento Notebook              |
|                    | **Reasonâ€‘mix** (these reasons are abnormally high in this region) | in Bento Notebook              |
|                    | **Productâ€‘vertical fit**                                          | in Bento Notebook              |
|                    | **Mixâ€‘vsâ€‘Efficiency decomposition**                               | in Bento Notebook              |
Only "Directional" hypothesis are root-cause and can be directly comparable. The rest are more "descriptive". They add visuals but how exactly do they compare to the rest requires further ranking. 

*May Goal: automate the rest, store all table in Hive â†’ Unidash; 
Slides keep only exec summary texts, ranked numbers and the more important images.*

---

## 2 Â· Root-Cause Hypothesis Types

### 2.1 Directional ("Dâ€‘score")

Most common, fully standardised â€“ works when KPI and hypothesis can be **ranked & compared across regions**.

**Scoring formula** *(weights will be discussed within DS team the Week of May 19th)*

```python
final_score = 0.5*direction_alignment \
            + 0.2*consistency          \
            + 0.2*hypo_z_norm          \
            + 0.1*explained_ratio
explains = final_score > 0.5
```

*Components â€“ 50â€¯/â€¯20â€¯/â€¯20â€¯/â€¯10â€¯%*  (see table)

| Component           | Meaning                                              | Implementation                 |
| ------------------- | ---------------------------------------------------- | ------------------------------ |
| Direction alignment | Metric & hypo move in expected dir                   | sign check (same / opposite)   |
| Consistency         | Strength of correlation across all regions           | `abs(Ï)`                       |
| Hypothesisâ€¯Z        | How far hypo in anomalous region is from global mean | bucket â†’ 1.0 / 0.7 / 0.6 / 0.3 |
| Explained ratio     |                                                      | min(Î”\_h/Î”\_m,1)               |

Output:  **Ranked Bar chart (based on hypothesis score) with Callout Texts**
Slide sample already in deck.

---

### 2.2 Depthâ€‘spotter

*What*: slice KPI â†’ L8; flag pockets Â±1â€¯Ïƒ from region mean.
*Why*: identifies **which subâ€‘markets actually drag L4**.

*Output*: bar chart of L8s sorted by zâ€‘score, coloured lag vs outâ€‘perform.


---

### 2.3 Mixâ€‘vsâ€‘Efficiency (Blinderâ€“Oaxaca)

*Useâ€‘case*: How much % of gap is due to better/worse composition, and how much is driven by performance?
*Breaks total gap into*

* **Mix / Composition** (employee job level mix, book construct revenue mix)
* **Efficiency** (withinâ€‘cell conversion).

Formula:
`Î”_total = Î£(mix_Râˆ’mix_ROW)Â·rate_ROW   +   Î£ mix_RÂ·(rate_Râˆ’rate_ROW)`

Visual: 2â€‘bar waterfall.


---

### 2.4 Productâ€‘mix index

*What*: regionâ€™s winâ€‘rate per product vs ROW baseline.
Outputs green/red index (>1 good, <1 needs review).
Helps answer: *â€œSwitch 5â€¯% pitches from P3 to P1 gives +1â€¯pp uplift.â€*

---

### 2.5 Reasonâ€‘mix (closedâ€‘lost or closed-won reasons)

% difference & dollar loss by AMâ€‘tagged reason â†’ categorical uplift table.


---

### 2.6 Productâ€‘vertical fit

1. Build global **product Ã— vertical** winâ€‘rate map (cells with winsâ€¯â‰¥â€¯30).
2. Keep topâ€‘k cells per vertical (bestâ€‘fit set).
3. Compare each regionâ€™s mix & withinâ€‘cell rates.
4. Simulate uplift if region reâ€‘allocates 5â€“10â€¯% pitches to bestâ€‘fit.

Visual: heatmap with region dots + waterfall (mix vs exec vs potential uplift).

---
## 3 Â· Open items for discussion

1. **Where does SSPO need drill/filters?** 
	1. What data needs to be populated in the Manager View spec?
2. **Slides vs Unidash split**. Slides remain the storybook; Unidash is the evidence warehouse.
	1. Which figures or component should remain in deck?
		1. 1. Exec one-pager: KPI heatmap/table & CTA bullets
		2. 1 PNG per flagged KPI 
		3. Narrative auto-filled from Hive Table
	2. What moves exclusively to Unidash? 
		* Hypothesis ranking table with sort / search
		* CI topic uplift matrix
		- Interactive heatmaps (product Ã— vertical)
		* (future) DFS drill from metric â†’ hypothesis â†’ leaf evidence 
		* (future) Stage-flow alluvial with hover counts
		* (future) Pacing curves & velocity tables
	3. How can we make the Unidash better to serve all layers of users?
3. **Dream Next Phase of Interaction** 

| Rank  | Impact | Rationale                                                                                                                                             | Who benefits                  |
| ----- | ------ | ----------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------- |
| **1** | ðŸ”´ðŸ”´ðŸ”´ | **Self-serve diagnostic filters (region, team, metric, date)** replace 1:1 deck requests; DS time goes to model improvements instead of slide re-cuts | SSPO frontline, Sales leaders |
| **2** | ðŸ”´ðŸ”´   | **LLM (Metamate) layer on top of live data**: *â€œCompare week 3 vs 9â€* / *â€œShow verticals common to all lagging L8sâ€* / surfacing AM comment excerpts  | All leadership tiers          |
| **3** | ðŸ”´ðŸ”´   | **Drill-to-evidence hover** (preview card with mini-waterfall + AM quotes) removes 5â€“10 slide hops per question                                       | VP reviews, QBR live demos    |
| **4** | ðŸ”´ðŸ”´   | **One canonical data source** (Hive / Manifold behind Unidash) â†’ DE can own orchestration; no copy-paste drift                                        | DE, Compliance                |
| **5** | ðŸ”´     | **Manager-view dashboards** reading from the same table power future SSPO roadmap without extra DS coding                                             | SSPO analytics                |
| **6** | ðŸ”´     | **Screenshot â†’ Slide** workflow still possible for weekly WBR deck; DS keeps only 3 static summary pages                                              | WBR owner                     |

---
## 4 Â· Next steps 

| When        | Deliverable                                                 |
| ----------- | ----------------------------------------------------------- |
